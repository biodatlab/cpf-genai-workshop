{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to prompt engineering\n",
    "\n",
    "*Prompt* เป็นการป้อนคำสั่งให้กับ large language model (LLM) เช่น GPT, Gemini, หรือ Llama เพื่อให้ได้มาซึ่งผลลัพธ์ที่ต้องการ ซึ่งต่อมาได้มีการพัฒนาเทคนิคต่างๆ ในการเขียน prompt ที่ทำให้ผลลัพธ์ที่ได้มีคุณภาพมากขึ้น ซึ่งเราเรียกเทคนิคเหล่านั้นว่า *prompt engineering*\n",
    "\n",
    "ใน Notebook นี้เราจะยกตัวอย่างการเขียน prompt และ เปรียบเทียบผลลัพธ์ที่ได้จาก Prompt และ โมเดลที่แตกต่างกัน\n",
    "โดยใช้ *LlamaIndex* ซึ่งเป็น เป็นเฟรมเวิร์กข้อมูลที่เรียบง่ายและยืดหยุ่นสำหรับเชื่อมต่อแหล่งข้อมูลที่กำหนดเองกับ LLM ที่เราต้องการ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**เริ่มต้นการใช้งาน LlamaIndex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries ที่จำเป็น\n",
    "import os\n",
    "from PIL import Image\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "from llama_index.core.schema import ImageDocument\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\"# ใส่ OpenAI API key ที่นี้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ใช้งาน GPT-4o ด้วย LlamaIndex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = OpenAI(model=\"gpt-4o\")\n",
    "response = openai_model.complete(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt ที่ดีควรจะมีส่วนประกอบดังนี้\n",
    "- Instruction : งานหรือคำสั่งที่ต้องการให้โมเดลทำ\n",
    "- Context : ข้อมูลภายนอกหรือบริบทเพิ่มเติมที่ช่วยให้โมเดลตอบได้ดีขึ้น\n",
    "- Input ข้อมูลหรือคำถามที่เราสนใจหาคำตอบ\n",
    "- Output Indicator : ประเภทหรือรูปแบบของผลลัพธ์ที่ต้องการ เช่น Tone, Length, Style\n",
    "\n",
    "ref: https://www.promptingguide.ai/introduction/elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Prompt Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_model.complete(\"Could you list down 5 stunning campaings ideas for my new product launch?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_prompt = \"\"\"\n",
    "In next year, we are going to launch a new food product which is a healthy snack bar.\n",
    "Could you list down 5 stunning campaings ideas for my new product launch?\n",
    "The campaign ideas should be in the following format:\n",
    "# Campaign Name 1 \n",
    "## Campaign Name\n",
    "- Campaign Objective\n",
    "- Campaign Target Audience\n",
    "- Indicators of Success\n",
    "\n",
    "# Campaign Name 2\n",
    "and so on...\n",
    "\n",
    "The audience for the campaign are Thai Gen Z so the campaign headline should contain some trendy words and in Thai language.\n",
    "\"\"\"\n",
    "campaign_lists = openai_model.complete(campaign_prompt)\n",
    "print(campaign_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เป็นการยกตัวอย่างเพียงเล็กน้อยเพื่อให้โมเดลสามารถตอบคำถามได้ตรงตามความต้องการ\\\n",
    "ref: https://www.promptingguide.ai/techniques/fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"\"\"\n",
    "Could you list down 5 catchphrases of Thai convenience store 7-Eleven\n",
    "The catchphrases should be catchy and trendy and must be in Thai language.\n",
    "\"\"\"\n",
    "baseline_resp = openai_model.complete(baseline)\n",
    "print(baseline_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Could you list down 5 catchphrases of Thai convenience store 7-Eleven\n",
    "The catchphrases should be catchy and trendy and must be in Thai language.\n",
    "here are some examples:\n",
    "- ไข่สด CP : ไข่สดซีพี เติมสิ่งดีๆ ให้กับชีวิต\n",
    "- CP : สด สะอาด ปลอดภัย มั่นใจทุกวัน\n",
    "- CP Fresh Mart : ทุกมื้อดีๆ ที่ซีพีเฟรชมาร์ท\n",
    "\"\"\"\n",
    "few_shot_resp = openai_model.complete(few_shot_prompt)\n",
    "print(few_shot_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain-of-Thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เป็นการบอกให้โมเดลใช้เหตุผลในการวิเคราะห์คำถาม หรือ คำสั่งก่อนที่จะตอบคำถาม CoT เป็นเทคนิคที่นิยมในการทำให้โมเดลสามารถแก้ปัญหาที่ซับซ้อนได้ดีขึ้น โดยแยกได้ 2 ประเภท คือ\n",
    "- *Chain-of-Thought (CoT) Prompting* ที่จะเป็นการใส่ลำดับความคิดเข้าไปใน prompt\n",
    "- *Zero-shot Chain-of-Thought (CoT) Prompting* เป็นการสั่งให้โมเดลคิดอย่างเป็นลำดับเพื่อให้ได้ผลลัพธ์ที่ต้องการ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_hardest_problem_for_llm = \"อยากให้เมื่อวานเป็นวันพรุ่งนี้จัง วันนี้จะได้เป็นวันศุกร์ วันนี้เป็นวันอะไร?\"\n",
    "baseline_resp = openai_model.complete(the_hardest_problem_for_llm)\n",
    "print(baseline_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = \"\"\"\n",
    "อยากให้เมื่อวานเป็นวันพรุ่งนี้จัง วันนี้จะได้เป็นวันศุกร์ วันนี้เป็นวันอะไร\n",
    "\n",
    "Let's think step by step:\n",
    "พรุ่งนี้ ในโลกจริง คือ เมื่อวาน ในโลกสมมติ\n",
    "เราอยากให้ วันนี้ในโลกสมมติ จะเป็นวันศุกร์ ดังนั้นเมื่อวานในโลกสมมติเป็นวันพฤหัสบดี\n",
    "ดังนั้น วันนี้ในโลกจริง คือ วันอะไร?\n",
    "\"\"\"\n",
    "cot_resp = openai_model.complete(cot)\n",
    "print(cot_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_zero_shot = \"\"\"\n",
    "อยากให้เมื่อวานเป็นวันพรุ่งนี้จัง วันนี้จะได้เป็นวันศุกร์ \n",
    "วันนี้เป็นวันอะไร\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "cot_zero_shot_resp = openai_model.complete(cot_zero_shot)\n",
    "print(cot_zero_shot_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multimodal with ChatGPT & LlmaIndex**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image from a path\n",
    "image_path = '../assets/seki_example.jpg'\n",
    "image = Image.open(image_path)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_mm_llm = OpenAIMultiModal(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Perform optical character information and export in the following JSON format.\n",
    "\n",
    "{\n",
    "  tax_id: str,\n",
    "  pos_id: str,\n",
    "  tel_number: str,\n",
    "  date: str,\n",
    "  recepit_number: str,\n",
    "  items: list[name, float],\n",
    "  price_before_vat: float,\n",
    "  total_price: float,\n",
    "  vat_7_percent: float,\n",
    "  earn_point: float\n",
    "}\n",
    "\"\"\"\n",
    "image_path = '../assets/seki_example.jpg'\n",
    "recipt = [ImageDocument(image_path=image_path)]\n",
    "answer = openai_mm_llm.complete(\n",
    "  prompt=question,\n",
    "  image_documents=recipt\n",
    ")\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explain Nong Moo Deng**\n",
    "\n",
    "ลองใส่ภาพน้องหมูเด้งแล้วทดลองใช้ ChatGPT อธิบายว่าทำไมน้องถึงเป็น Viral ในโลกออนไลน์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\\\n",
    "You are a helpful assistant designed to interpret the image and see why the given image gets viral online. You should provide an answer in Thai.\n",
    "Give an image, please explain why the given image of 'หมูเด้ง', a baby hippo, is viral online?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../assets/moodeng.jpg\"\n",
    "moo_deng = [ImageDocument(image_path=image_path)]\n",
    "answer = openai_mm_llm.complete(\n",
    "  prompt=question,\n",
    "  image_documents=moo_deng\n",
    ")\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLM อื่นๆที่น่าสนใจ**\n",
    "\n",
    "- SeaLLM (Alibaba DAMO) https://huggingface.co/spaces/SeaLLMs/SeaLLM-Chat-13b\n",
    "- Vertex AI (Google) https://cloud.google.com/vertex-ai?hl=en\n",
    "- Typhoon (SCBX) https://opentyphoon.ai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
