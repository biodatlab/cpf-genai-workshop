{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806f4d92",
   "metadata": {},
   "source": [
    "## **Prompting with Gemini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.generative_models import GenerativeModel, Part, Image\n",
    "\n",
    "project_name = \"...\" # ใส่ชื่อ project ที่นี้\n",
    "credentials = service_account.Credentials.from_service_account_file(\"...\") # ใส่ path ไปยัง JSON file ที่นี่\n",
    "aiplatform.init(project=project_name, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt, model_name=\"gemini-1.5-flash\"):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันสำหรับรับคำตอบจากโมเดล AI\n",
    "    \n",
    "    Args:\n",
    "    prompt (str): คำถามหรือข้อความที่ต้องการให้ AI ตอบ\n",
    "    model_name (str): ชื่อของโมเดลที่ต้องการใช้ (ค่าเริ่มต้นคือ \"gemini-1.5-flash\")\n",
    "    \n",
    "    Returns:\n",
    "    str: ข้อความตอบกลับจาก AI\n",
    "    \"\"\"\n",
    "    model = GenerativeModel(model_name)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70639d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_response(\"Why is sky blue?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f8c8b",
   "metadata": {},
   "source": [
    "## **Prompting Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdef518",
   "metadata": {},
   "source": [
    "## **Prompt Engineering**\n",
    "\n",
    "Prompt ที่ดีควรจะมีส่วนประกอบดังนี้\n",
    "- Instruction : งานหรือคำสั่งที่ต้องการให้โมเดลทำ\n",
    "- Context : ข้อมูลภายนอกหรือบริบทเพิ่มเติมที่ช่วยให้โมเดลตอบได้ดีขึ้น\n",
    "- Input ข้อมูลหรือคำถามที่เราสนใจหาคำตอบ\n",
    "- Output Indicator : ประเภทหรือรูปแบบของผลลัพธ์ที่ต้องการ เช่น Tone, Length, Style\n",
    "\n",
    "ref: https://www.promptingguide.ai/introduction/elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eec981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "response = get_response(\"Could you list down 5 stunning campaings ideas for my new product launch?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_prompt = \"\"\"\n",
    "In next year, we are going to launch a new food product which is a healthy snack bar.\n",
    "Could you list down 5 stunning campaings ideas for my new product launch?\n",
    "The campaign ideas should be in the following format:\n",
    "# Campaign Name 1 \n",
    "## Campaign Name\n",
    "- Campaign Objective\n",
    "- Campaign Target Audience\n",
    "- Indicators of Success\n",
    "\n",
    "# Campaign Name 2\n",
    "and so on...\n",
    "\n",
    "The audience for the campaign are Thai Gen Z so the campaign headline should contain some trendy words and in Thai language.\n",
    "\"\"\"\n",
    "campaign_lists = get_response(campaign_prompt)\n",
    "print(campaign_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27b99b",
   "metadata": {},
   "source": [
    "#### Few-shot Prompting\n",
    "เป็นการยกตัวอย่างเพียงเล็กน้อยเพื่อให้โมเดลสามารถตอบคำถามได้ตรงตามความต้องการ\\\n",
    "ref: https://www.promptingguide.ai/techniques/fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1dba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"\"\"\n",
    "Could you list down 5 catchphrases of Thai convenience store 7-Eleven\n",
    "The catchphrases should be catchy and trendy and must be in Thai language.\n",
    "\"\"\"\n",
    "baseline_resp = get_response(baseline)\n",
    "print(baseline_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Could you list down 5 catchphrases of Thai convenience store 7-Eleven\n",
    "The catchphrases should be catchy and trendy and must be in Thai language.\n",
    "here are some examples:\n",
    "- ไข่สด CP : ไข่สดซีพี เติมสิ่งดีๆ ให้กับชีวิต\n",
    "- CP : สด สะอาด ปลอดภัย มั่นใจทุกวัน\n",
    "- CP Fresh Mart : ทุกมื้อดีๆ ที่ซีพีเฟรชมาร์ท\n",
    "\"\"\"\n",
    "few_shot_resp = get_response(few_shot_prompt)\n",
    "print(few_shot_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde8718",
   "metadata": {},
   "source": [
    "#### Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "เป็นการบอกให้โมเดลใช้เหตุผลในการวิเคราะห์คำถาม หรือ คำสั่งก่อนที่จะตอบคำถาม CoT เป็นเทคนิคที่นิยมในการทำให้โมเดลสามารถแก้ปัญหาที่ซับซ้อนได้ดีขึ้น โดยแยกได้ 2 ประเภท คือ\n",
    "- *Chain-of-Thought (CoT) Prompting* ที่จะเป็นการใส่ลำดับความคิดเข้าไปใน prompt\n",
    "- *Zero-shot Chain-of-Thought (CoT) Prompting* เป็นการสั่งให้โมเดลคิดอย่างเป็นลำดับเพื่อให้ได้ผลลัพธ์ที่ต้องการ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e649a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_hardest_problem_for_llm = \"อยากให้เมื่อวานเป็นวันพรุ่งนี้จัง วันนี้จะได้เป็นวันศุกร์ วันนี้เป็นวันอะไร?\"\n",
    "# คำตอบที่ถูกต้องคือ วันพุธ หรือ วันอาทิตย์\n",
    "baseline_resp = get_response(the_hardest_problem_for_llm)\n",
    "print(baseline_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = \"\"\"\n",
    "อยากให้เมื่อวานเป็นวันพรุ่งนี้จัง วันนี้จะได้เป็นวันศุกร์ วันนี้เป็นวันอะไร\n",
    "\n",
    "Let's think step by step:\n",
    "พรุ่งนี้ ในโลกจริง คือ เมื่อวาน ในโลกสมมติ\n",
    "เราอยากให้ วันนี้ในโลกสมมติ จะเป็นวันศุกร์ ดังนั้นเมื่อวานในโลกสมมติเป็นวันพฤหัสบดี\n",
    "เราอยากให้พรุ่งนี้ในโลกจริง เป็นเมื่อวานในโลกสมมติซึงเป็น วันพฤหัสบดี\n",
    "ดังนั้น วันนี้ในโลกจริง คือ วันอะไร?\n",
    "\"\"\"\n",
    "cot_resp = get_response(cot)\n",
    "print(cot_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_zero_shot = \"\"\"\n",
    "อยากให้เมื่อวานเป็นวันพรุ่งนี้จัง วันนี้จะได้เป็นวันศุกร์ วันนี้เป็นวันอะไร\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "cot_zero_shot_resp = get_response(cot_zero_shot)\n",
    "print(cot_zero_shot_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a51e01",
   "metadata": {},
   "source": [
    "## **Multimodal with Gemini**\n",
    "\n",
    "\n",
    "อ่านเพิ่มเติม:\n",
    "- https://cloud.google.com/vertex-ai/generative-ai/docs/samples/generativeaionvertexai-gemini-all-modalities#generativeaionvertexai_gemini_all_modalities-python\n",
    "- https://cloud.google.com/vertex-ai/generative-ai/docs/reference/python/latest/vertexai.vision_models.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0280412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_with_image(prompt, image_path, model_name=\"gemini-pro-vision\"):\n",
    "    \"\"\"\n",
    "    ฟังก์ชันสำหรับรับคำตอบจากโมเดล AI โดยใช้รูปภาพประกอบ\n",
    "    \n",
    "    Args:\n",
    "    prompt (str): คำถามหรือข้อความที่ต้องการให้ AI ตอบ\n",
    "    image_path (str): พาธของไฟล์รูปภาพ\n",
    "    model_name (str): ชื่อของโมเดลที่ต้องการใช้ (ค่าเริ่มต้นคือ \"gemini-pro-vision\")\n",
    "    \n",
    "    Returns:\n",
    "    str: ข้อความตอบกลับจาก AI\n",
    "    \"\"\"\n",
    "\n",
    "    model = GenerativeModel(model_name)\n",
    "    image = Image.load_from_file(image_path)\n",
    "\n",
    "    # สร้างคำตอบจากโมเดล\n",
    "    response = model.generate_content([image, prompt])\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fef39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Perform optical character information and export in the following JSON format.\n",
    "\n",
    "{\n",
    "  tax_id: str,\n",
    "  pos_id: str,\n",
    "  tel_number: str,\n",
    "  date: str,\n",
    "  recepit_number: str,\n",
    "  items: list[name, float],\n",
    "  price_before_vat: float,\n",
    "  total_price: float,\n",
    "  vat_7_percent: float,\n",
    "  earn_point: float\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "answer = get_response_with_image(prompt, \"../assets/seki_example.jpg\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749a853",
   "metadata": {},
   "source": [
    "## **Explain Nong Moo Deng**\n",
    "\n",
    "ลองใส่ภาพน้องหมูเด้งแล้วทดลองใช้ ChatGPT อธิบายว่าทำไมน้องถึงเป็น Viral ในโลกออนไลน์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ac41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "You are a helpful assistant designed to interpret the image and see why the given image gets viral online. You should provide an answer in Thai.\n",
    "Give an image, please explain why the given image of 'หมูเด้ง', a baby hippo, is viral online?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../assets/moodeng.jpg\"\n",
    "output = get_response_with_image(prompt, image_path)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
